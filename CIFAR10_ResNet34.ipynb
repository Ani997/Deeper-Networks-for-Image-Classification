{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_ResNet34.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6ZBuTzNPZk"
      },
      "source": [
        "# Importing the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from statistics import mean\n",
        "import datetime as datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6_0NUPVNSHJ"
      },
      "source": [
        "# Data pre-processing\n",
        "transform_train = transforms.Compose([transforms.Resize((70,70)), # Resizing the dataset samples to 70x70\n",
        "                                transforms.RandomHorizontalFlip(), # Randomly flips the data samples horizontally\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), # Normalizing the dataset\n",
        "                                                     (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform_test = transforms.Compose([transforms.Resize((70,70)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), \n",
        "                                                     (0.5, 0.5, 0.5))])                                                    \n",
        "\n",
        "# Downloading and loading the dataset into the workspace\n",
        "train = torchvision.datasets.CIFAR10(root='./data',train=True, transform=transform_train, download=True)\n",
        "test = torchvision.datasets.CIFAR10(root='./data',train=False, transform=transform_test, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=32, shuffle=False)\n",
        "cuda = torch.device('cuda') # training the model on a GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrQajvPlNUcQ"
      },
      "source": [
        "# Structure of the ResNet-34 architecture\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet34(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super().__init__()    \n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 , num_classes)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None     \n",
        "        if stride != 1 or self.inplanes != planes:\n",
        "            downsample = nn.Sequential(nn.Conv2d(self.inplanes, planes, 1, stride, bias=False),\n",
        "                                       nn.BatchNorm2d(planes))\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        \n",
        "        self.inplanes = planes\n",
        "        \n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)          \n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)         \n",
        "\n",
        "        x = self.layer1(x)         \n",
        "        x = self.layer2(x)          \n",
        "        x = self.layer3(x)         \n",
        "        x = self.layer4(x)          \n",
        "\n",
        "        x = self.avgpool(x)        \n",
        "        x = torch.flatten(x, 1)     \n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet34():\n",
        "    layers=[3, 4, 6, 3]\n",
        "    model = ResNet34(Bottleneck, layers)\n",
        "    return model\n",
        "\n",
        "model = resnet34()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8NKsalFNp54"
      },
      "source": [
        "model = model.cuda() # Using CUDA enabled GPU for training the model\n",
        "loss = nn.CrossEntropyLoss() # Using Cross Entropy as Loss function\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # Setting the optimizer for training the model\n",
        "cost = 0\n",
        "epochs = 20 # Setting the number of epochs for which the model is to be trained\n",
        "\n",
        "iterations = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for X, Y in train_loader:\n",
        "        X = X.to(cuda)\n",
        "        Y = Y.to(cuda)\n",
        "        optimizer.zero_grad()\n",
        "        hypo = model(X)\n",
        "        cost = loss(hypo, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "        prediction = hypo.data.max(1)[1]\n",
        "        correct += prediction.eq(Y.data).sum()\n",
        "\n",
        "    model.eval()\n",
        "    correct2 = 0\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(cuda)\n",
        "        target = target.to(cuda)\n",
        "        output = model(data)\n",
        "        cost2 = loss(output, target)\n",
        "        prediction = output.data.max(1)[1]\n",
        "        correct2 += prediction.eq(target.data).sum()\n",
        "\n",
        "    iterations.append(epoch)\n",
        "    train_losses.append(cost.tolist())\n",
        "    test_losses.append(cost2.tolist())\n",
        "    train_acc.append((100*correct/len(train_loader.dataset)).tolist())\n",
        "    test_acc.append((100*correct2/len(test_loader.dataset)).tolist())\n",
        "    print(\"Epoch : {:>4} / cost : {:>.9}\".format(epoch + 1, cost))\n",
        "    print('Train set Accuracy: {:.2f}%'.format(100. * correct / len(train_loader.dataset)))\n",
        "    print('Test set Accuracy: {:.2f}%'.format(100. * correct2 / len(test_loader.dataset)))\n",
        "    timestamp = datetime.datetime.now()\n",
        "    print(\"Date, Time stamp: \", timestamp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Col9CdheN1-7"
      },
      "source": [
        "# Train Accuracy vs Validation accuracy plot\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_acc, color='green', label='train accuracy')\n",
        "plt.plot(test_acc, color='blue', label='validataion accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "# Train Loss vs Validation Loss plot\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_losses, color='orange', label='train loss')\n",
        "plt.plot(test_losses, color='red', label='validataion loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqqHUNeN5EY"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Utilizng CUDA enabled GPU\n",
        "print(device)\n",
        "classes = ['airplane','automobile','bird', # Classes of the CIFAR-10 dataset\n",
        "           'cat','deer','dog','frog',\n",
        "           'horse','ship','truck']\n",
        "\n",
        "# Building the heatmap of the correctly classified and misclassified data samples\n",
        "heatmap = pd.DataFrame(data=0,index=classes,columns=classes)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(16):\n",
        "            true_label = labels[i].item()\n",
        "            predicted_label = predicted[i].item()\n",
        "            heatmap.iloc[true_label,predicted_label] += 1\n",
        "_, ax = plt.subplots(figsize=(10, 8))\n",
        "ax = sns.heatmap(heatmap, annot=True, fmt='d',cmap='YlGnBu')\n",
        "figure = ax.get_figure()    \n",
        "figure.savefig('heatmap.png', dpi=400)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aetyZvR_N7u4"
      },
      "source": [
        "# Saving the model\n",
        "torch.save(model,'ResNet34_CIFAR10.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}